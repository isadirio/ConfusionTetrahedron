{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fef7d04",
   "metadata": {},
   "source": [
    "# 1. Load cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloaded the dataset from the UCI repository archive \n",
    "#(https://archive.ics.uci.edu/ml/datasets/chronic_kidney_disease)\n",
    "\n",
    "#decompressed the RAR file \n",
    "#turned the arff file into csv (using Python converter)\n",
    "\n",
    "# now loading full csv into the notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f2b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/cleaned.csv', header = 0, on_bad_lines='skip')\n",
    "data = data.drop(data.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ba9e4",
   "metadata": {},
   "source": [
    "# 2. Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff4794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0be972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable\n",
    "y = data['class']\n",
    "y\n",
    "\n",
    "#predictors\n",
    "x = data.copy()\n",
    "x.drop('class', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "#testsize not too big  because I have relatively few records\n",
    "#randomstate for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eee5d5",
   "metadata": {},
   "source": [
    "# 3. Fitting classification models and first performance assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d71f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ade260",
   "metadata": {},
   "source": [
    "## 3.1 Linear methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faba716a",
   "metadata": {},
   "source": [
    "### 3.1.1  Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba95102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learns the probability of a sample belonging to a certain class \n",
    "\n",
    "# discriminative model \n",
    "#(=directly models the posterior probability of P(y|x) y learning the input to output mapping by minimising error)\n",
    "#                      #posterior=update of prob of event A happening given new info as event B happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abea9fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = timeit.default_timer() #for all models I record the time\n",
    "\n",
    "#instance of the model \n",
    "logreg = LogisticRegression()\n",
    "\n",
    "#the model learns the relationship between predictors and label \n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#predict the label on test set \n",
    "predictionsLR = logreg.predict(X_test)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) \n",
    "\n",
    "predictionsLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f910f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmLR = confusion_matrix(y_test,predictionsLR)\n",
    "cmLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOW PRIORITY\n",
    "#TODO: Definire un'unica funzione per tutte le metriche invece che definirle una per una ogni volta \n",
    "\n",
    "\"\"\"\n",
    "def matrix_metrix(real_values,pred_values):\n",
    "    CM = confusion_matrix(real_values,pred_values) #get confusion matrix\n",
    "    \n",
    "    TN = CM[0][0]     #confusion matrix entries and n° of samples\n",
    "    FN = CM[1][0] \n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    tot = TN+FN+TP+FP\n",
    "    \n",
    "    #performance metrics with 2 matrix entries\n",
    "    Prevalence = round( (TP+FP) /tot,2)\n",
    "    Accuracy   = round( (TP+TN) / tot,4)\n",
    "    Precision  = round( TP / (TP+FP),4 )\n",
    "    NPV        = round( TN / (TN+FN),4 ) \n",
    "    FDR        = round( FP / (TP+FP),4 )\n",
    "    FOR        = round( FN / (TN+FN),4 ) \n",
    "    check_Pos  = Precision + FDR\n",
    "    check_Neg  = NPV + FOR\n",
    "    \n",
    "    #performance metrics with more than 2 entries -> more comprehensive metrics\n",
    "    Recall     = round( TP / (TP+FN),4 )\n",
    "    FPR        = round( FP / (TN+FP),4 ) #false positive rate\n",
    "    FNR        = round( FN / (TP+FN),4 ) #false negative rate\n",
    "    TNR        = round( TN / (TN+FP),4 ) #true negative rate \n",
    "    check_Pos2 = Recall + FNR\n",
    "    check_Neg2 = FPR + TNR\n",
    "    \n",
    "    LRPos      = round( Recall/FPR, 4 )   #positive likelihood\n",
    "    LRNeg      = round( FNR / TNR ,4 )   #negative likelihood \n",
    "    \n",
    "    DOR        = round( LRPos/LRNeg)\n",
    "    F1         = round ( 2 * ((Precision*Recall)/(Precision+Recall)),4)\n",
    "    #FBeta      = round ( (1+beta**2)*((Precision*Recall)/((beta**2 * Precision)+ Recall)) ,4)\n",
    "    MCC        = round ( ((TP*TN)-(FP*FN))/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))  ,4)\n",
    "    BM         = Recall+TNR-1\n",
    "    MK         = Precision+NPV-1\n",
    "    mat_met = pd.DataFrame({\n",
    "        'Metric':['TP','TN','FP','FN','Prevalence','Accuracy','Precision','NPV','FDR','FOR','check_Pos','check_Neg','Recall','FPR','FNR','TNR','check_Pos2','check_Neg2','LR+','LR-','DOR','F1','MCC','BM','MK'], #,'FBeta'    \n",
    "        'Value':[TP,TN,FP,FN,Prevalence,Accuracy,Precision,NPV,FDR,FOR,check_Pos,check_Neg,Recall,FPR,FNR,TNR,check_Pos2,check_Neg2,LRPos,LRNeg,DOR,F1,MCC,BM,MK]}) #FBeta\n",
    "    return (mat_met)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b64ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOR = (TP / (TP+FN)/FP / (TN+FP))/(FN / (TP+FN)/TN / (TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd2984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "\n",
    "accuracyLR = round(logreg.score(X_test, y_test),4)\n",
    "print(accuracyLR)\n",
    "\n",
    "\n",
    "#COMPREHENSIVE METRICS\n",
    "\n",
    "#MCC/phi coefficient\n",
    "#essentially a correlation coefficient between -1(inverse prediction) and 1 (with being 0 average random prediction)\n",
    "#takes into account true and false positives and negatives \n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html\n",
    "MCCLR = round(matthews_corrcoef(y_test, predictionsLR),4)\n",
    "print(MCCLR)\n",
    "\n",
    "\n",
    "#DOR \n",
    "#=TP/FN*FP/TN\n",
    "#DOR = (TP / (TP+FN)/FP / (TN+FP))/(FN / (TP+FN)/TN / (TN+FP))\n",
    "TPLR = cmLR[0][0]\n",
    "FNLR = cmLR[0][1]\n",
    "FPLR = cmLR[1][0]\n",
    "TNLR = cmLR[1][1]\n",
    "\n",
    "#DOR = TPLR/FNLR*FPLR/TNLR\n",
    "#print(DOR)\n",
    "\n",
    "\n",
    "#F1_score = harmonic mean of precision and recall (0=worst, 1=best)\n",
    "#F1=2*(precision*recall)/(precision+recall)\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "F1LR = f1_score(y_test, predictionsLR, \n",
    "                average=None) #only required for multiclass targets\n",
    "print(F1LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7252a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(cm): \n",
    "    import math\n",
    "        \n",
    "    TN = cm[0][0]     #confusion matrix entries and n° of samples\n",
    "    FN = cm[1][0] \n",
    "    TP = cm[1][1]\n",
    "    FP = cm[0][1]\n",
    "    tot = TN+FN+TP+FP\n",
    "    \n",
    "    accuracy = round( (TP+TN) / tot,4)\n",
    "    precision = round( TP / (TP+FP),4 )\n",
    "    recall = round( TP / (TP+FN),4 )\n",
    "    MCC = round ( ((TP*TN)-(FP*FN))/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))  ,4)\n",
    "    F1 = round ( 2 * ((precision*recall)/(precision+recall)),4)\n",
    "    mat_met = pd.DataFrame({\n",
    "        'Metric':['Accuracy','Precision','Recall','F1','MCC'],\n",
    "        'Value':[accuracy,precision,recall,F1,MCC]}) \n",
    "    return (mat_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(cmLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec051176",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cmLR, annot=True, linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Logistic Regression \\n Accuracy Score: {0} \\n MCC score: {1}'.format(round(accuracyLR,4),round(MCCLR,4))\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23050399",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cmLR, annot=True,annot_kws={\"size\": 35 / np.sqrt(len(cmLR))}, linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Logistic Regression \\n Accuracy Score: {0}\\n MCC Score: {1}\\n'.format(round(accuracyLR,4),'0.9835')\n",
    "plt.title(all_sample_title, size = 17,fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#molto alto \n",
    "\n",
    "#errore è effettivamente sul test quindi sta performando molto bene \n",
    "#che è un po' sospetto ma vedo prima tutti gli altri\n",
    "\n",
    "#assumptions della logreg: \n",
    "#- independence of errors, \n",
    "#- linearity in the logit for continuous variables, \n",
    "#- absence of multicollinearity\n",
    "#- lack of strongly influential outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582769d3",
   "metadata": {},
   "source": [
    "### 3.1.2  Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes classifier assumes that the effect of a particular feature in a class is independent of other features\n",
    "\n",
    "#1. calculates prior probability for a given class label \n",
    "#2. calculate conditional probability with each attribute for each class\n",
    "#3. multiply same class conditional probability\n",
    "#4. multiply prior probability with step 3 probability\n",
    "#5. sees which class has higher probability, higher probability class belongs to given input set step\n",
    "\n",
    "# generative model\n",
    "# (= models the joint distribution of the feature X and the targetY, \n",
    "#    and then predicts the posterior probability given as P(y|x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9be896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the model \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#make an instance of the model \n",
    "NB = GaussianNB()\n",
    "\n",
    "#make the model learn the relationship between predictors and label \n",
    "NB.fit(X_train, y_train)\n",
    "\n",
    "#predict the label on test set \n",
    "predictionsNB = NB.predict(X_test)\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) \n",
    "\n",
    "predictionsNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d07c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmNB = confusion_matrix(y_test,predictionsNB)\n",
    "cmNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2239cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(cmNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c0ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyNB = NB.score(X_test, y_test)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cmNB, annot=True, linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Naive Bayes \\nAccuracy Score: {0} \\n MCC score: {1}'.format(round(accuracyNB,4), '0.9677' )\n",
    "plt.title(all_sample_title, size = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7dcee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cmNB, annot=True,annot_kws={\"size\": 35 / np.sqrt(len(cmNB))}, linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Naive Bayes \\n Accuracy Score: {0}\\n MCC Score: {1}\\n'.format(round(accuracyNB,4),'0.9677')\n",
    "plt.title(all_sample_title, size = 17,fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70356b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anche questo molto alto \n",
    "#ma probabilmente è solo che i modelli lineari si prestano particolarmente a questo dataset \n",
    "#che è piccolo, non high dimensional e abbastanza omogeneo (anche per come sono ho gestito i missing values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457641c7",
   "metadata": {},
   "source": [
    "## 3.2 Non linear: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90960ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#does not make any assumption on the data distribution (non parametric)\n",
    "\n",
    "#KNN can be summarized as below:\n",
    "#1.Computes the distance between the new data point with every training example.\n",
    "#2.For computing the distance measures such as Euclidean distance, Hamming distance or Manhattan distance will be used.\n",
    "#3.Model picks K entries in the database which are closest to the new data point.\n",
    "#4.Then it does the majority vote i.e the most common class/label among those K entries will be the class of the new data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a507f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the model \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#different K to check which to choose\n",
    "k_range = range(1,26)\n",
    "scores = {}\n",
    "scores_list = []\n",
    "for k in k_range: \n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train,y_train)\n",
    "    predKNN = knn.predict(X_test)\n",
    "    scores[k] = metrics.accuracy_score(y_test,predKNN)\n",
    "    scores_list.append(metrics.accuracy_score(y_test,predKNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3dd7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot(k_range, scores_list)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "\n",
    "#best appears to be at 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1271ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "predKNN_3k = knn.predict(X_test)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) \n",
    "\n",
    "predKNN_3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ccf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmKNN = metrics.confusion_matrix(y_test,predKNN_3k)\n",
    "cmKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(cmKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eae521",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyKNN = knn.score(X_test, y_test)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cmKNN, annot=True, linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'KNN \\n Accuracy Score: {0} \\n MCC Score: {1}'.format(round(accuracyKNN,4), 0.5679)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cmKNN, annot=True,annot_kws={\"size\": 35 / np.sqrt(len(cmKNN))}, linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'K-Nearest Neighbors \\n Accuracy Score: {0}\\n MCC Score: {1}\\n'.format(round(accuracyKNN,4),'0.5679')\n",
    "plt.title(all_sample_title, size = 17,fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8059ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#particolarmente basso rispetto agli altri \n",
    "\n",
    "#probabilmente appunto è la questione della linearità perchè pure i tree performano peggio "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65662d69",
   "metadata": {},
   "source": [
    "## 3.3 Tree based methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfee7f2",
   "metadata": {},
   "source": [
    "Tend to overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3920161c",
   "metadata": {},
   "source": [
    "### 3.3.1 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a396a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE\n",
    "\n",
    "#import model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#make instance of the model \n",
    "dt = DecisionTreeClassifier(random_state=33)\n",
    "\n",
    "#fit the classifier\n",
    "dt = dt.fit(X_train, y_train)\n",
    "\n",
    "#predict response\n",
    "predDT = dt.predict(X_test)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) \n",
    "\n",
    "predDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd236456",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmDT = metrics.confusion_matrix(y_test,predDT)\n",
    "cmDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(cmDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128c7354",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyDT = dt.score(X_test, y_test)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cmDT, annot=True, linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Decision Tree \\n Accuracy Score: {0} \\n MCC score: {1}'.format(round(accuracyDT,4),'0.9178')\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f23364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cmDT, annot=True,annot_kws={\"size\": 35 / np.sqrt(len(cmDT))}, linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Decision Tree \\n Accuracy Score: {0}\\n MCC Score: {1}\\n'.format(round(accuracyDT,4),'0.9178')\n",
    "plt.title(all_sample_title, size = 17,fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c244fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(cmDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#con i tree va peggio - coerente con il peggioramento del KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48357ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!Pip install graphviz\n",
    "#!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df66a778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from six import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b361883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "#from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    " \n",
    "dot_data = StringIO()\n",
    "export_graphviz(dt, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = list(X_train.columns),class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('DecisionTree.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505e2a3",
   "metadata": {},
   "source": [
    "### 3.3.2 Bagging Decision Tree (Ensemble learning I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a4c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking bootstraps from the training data (=bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf01434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a7d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "bg = BaggingClassifier(DecisionTreeClassifier(), \n",
    "                      max_samples = 0.5,  #maximum size: 50% di tutto il dataset per ogni sample\n",
    "                      max_features = 1.0, #maximum of features: con 1 è 100% quindi tutte le 48 features\n",
    "                      n_estimators = 10)  #number of estimators: il numero di decision trees\n",
    "\n",
    "bg.fit(X_train, y_train)\n",
    "\n",
    "predBG = bg.predict(X_test)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) \n",
    "\n",
    "predBG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24000e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmBG = metrics.confusion_matrix(y_test,predBG)\n",
    "cmBG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8db2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyBG = dt.score(X_test, y_test)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cmBG, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score for Tree with Bagging: {0}'.format(accuracyBG)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#potrei anche risparmiare questi altri modelli di tree dato che già capisco che tree is not the way to go\n",
    "#ma voglio vedere se è così peggiorata perchè è solo un tree o con gli ensemble migliora\n",
    "\n",
    "#perchè i tree hanno la tendenza a overfittare in generale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9addfe8",
   "metadata": {},
   "source": [
    "### 3.3.3 Boosted Decision Tree (Ensemble learning II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02dffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd434d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer() \n",
    "\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(min_samples_split=10,\n",
    "                                                max_depth=4),\n",
    "                                               n_estimators=10,\n",
    "                                               learning_rate=0.6)\n",
    "\n",
    "adb.fit(X_train, y_train)\n",
    "\n",
    "predBS = adb.predict(X_test)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)\n",
    "predBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29de427",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmBS = metrics.confusion_matrix(y_test,predBS)\n",
    "cmBS #tutti true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyBS = dt.score(X_test, y_test)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cmBS, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score for Tree with Boosting (AdaBoost): {0}'.format(accuracyBS)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db90c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ormai è accanimento terapeutico ma a questo punto vedo anche con random fores\n",
    "\n",
    "#se facessi più valutazioni sugli iperparametri forse migliorerebbe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9252c4b",
   "metadata": {},
   "source": [
    "### 3.3.4 Random Forest (Ensemble learning III)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d9cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb432e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=30, max_depth=9)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predRF = rf.predict(X_test)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "predRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a1272",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmRF = metrics.confusion_matrix(y_test,predRF)\n",
    "cmRF #tutti true \n",
    "accuracyRF = dt.score(X_test, y_test)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cmRF, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score for Tree with Random Forests: {0}'.format(accuracyRF)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8745018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#va beh sembra che con quelli lineari vada meglio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc23d6",
   "metadata": {},
   "source": [
    "## 3.4 Support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99be966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel (=transforms an input data space into the required form) trick to handle nonlinear input spaces \n",
    "#(to transform the input space to a higher dimensional space so that \n",
    "#then one can easily separate the classes using linear separation)\n",
    "\n",
    "#The classifier separates data points using a hyperplane with the largest amount of margin. \n",
    "#That's why an SVM classifier is also known as a discriminative classifier. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "vect = svm.SVC(kernel='linear')\n",
    "\n",
    "vect.fit(X_train, y_train)\n",
    "\n",
    "predvect = vect.predict(X_test)\n",
    "\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "predvect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b3dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmSVM = metrics.confusion_matrix(y_test,predvect)\n",
    "accuracySVM = vect.score(X_test, y_test)\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cmSVM, annot=True,annot_kws={\"size\": 35 / np.sqrt(len(cmSVM))}, linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Support Vector Machines \\n Accuracy Score: {0}\\n MCC Score: {1}\\n'.format(round(accuracySVM,4),'0.9672')\n",
    "plt.title(all_sample_title, size = 17,fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd328e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cd6934",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(cmSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4bdabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#questo performa bene ma più tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f255ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters:\n",
    "#-kernel\n",
    "#-regularization\n",
    "#–gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a7fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#advantages:\n",
    "#–good accuracy and faster predictions wrt NB\n",
    "#-less memory usage because it uses a subset of training points in the decision phase\n",
    "#-works well with high dimensional space (here the features are not too many so the advantage is not extremely \n",
    "# harnessed but still good performance)\n",
    "\n",
    "#disadvantages:\n",
    "#-not suitable for large datasets because of high training time (non è questo il caso)\n",
    "#–sensitive to the type of kernel used "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3462ae1b",
   "metadata": {},
   "source": [
    "# 4. Visualization of the tetrahedron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c71f6",
   "metadata": {},
   "source": [
    "# Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f584909",
   "metadata": {},
   "source": [
    "Built on top of the Plotly Javascript library (plotly.js), Plotly is an open-source plotting library that enables the creation of interactive web-based visualizations. I use Plotly for three main reasons:  \n",
    "- extreme customization\n",
    "- possibility to display visualizations within Jupyter Notebooks, to save them to standalone html files but also to serve them as part of analytical web-applications using Dash (https://dash.plotly.com/installation) \n",
    "<br>\n",
    "\n",
    "An alternative could have been Ipyvolume which is still open source "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11cf829",
   "metadata": {},
   "source": [
    "#Python's visualisation landscape\n",
    "#using markdown ![viz](viz_landscape.jpeg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#riprendo le cm dai modelli\n",
    "cmLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bfcea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae858e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a0a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f71415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmDT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisco una confusion matrix che risulterebbe da una classificazione non auspicabile \n",
    "#per avere l'esempio del punto nel teatredro se poor performance\n",
    "cm_badc=np.array([[10,30],\n",
    "         [55,5]])           #confusion matrix fittizia\n",
    "cm_badc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e8d16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#PARTIAL RESULT \n",
    "\n",
    "#TETRAEDRO MESH CON PUNTI DEI MODELLI\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Mesh3d(\n",
    "        x=[0, 0, 0, 1], #verticalmente ho definito O, C, B, A\n",
    "        y=[0, 0, 1, 0],\n",
    "        z=[0, 1, 0, 0],\n",
    "        \n",
    "        colorbar_title='z',\n",
    "        \n",
    "        colorscale=[[0, 'gold'],\n",
    "                    [0.5, 'mediumturquoise'],\n",
    "                    [1, 'magenta']],\n",
    "        \n",
    "        #colors = colorRamp(c(\"red\",'yellow','white','green','blue')),\n",
    "        \n",
    "        # Intensity of each vertex, which will be interpolated \n",
    "        #and color-coded\n",
    "        intensity=[0, 0.33, 0.66, 1],\n",
    "        \n",
    "        opacity = 0.5, #for transparency\n",
    "        \n",
    "        # i, j and k sono i vertici dei triangoli\n",
    "        # here we represent the 4 triangles of the tetrahedron surface\n",
    "        i=[0, 0, 0, 1],\n",
    "        j=[1, 2, 3, 2],\n",
    "        k=[2, 3, 1, 3],\n",
    "        name='y',\n",
    "        showscale=True\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "#PRIMA QUESTIONE \n",
    "#aggiungere il punto per la confusion matrix dello use case specifico \n",
    "#-> risolto, non metto tutti i modelli ma tipo i due migliori e uno meno performante (da confusion matrix esempio)\n",
    "\n",
    "#Modello LogReg \n",
    "N = sum(sum(cmLR))                  #confusion matrix entries divided by N\n",
    "xLR = [cmLR[0][0]/N] #TP/N\n",
    "yLR = [cmLR[1][1]/N] #TN/N\n",
    "zLR = [cmLR[0][1]/N] #FP/N\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xLR, \n",
    "                           y= yLR, \n",
    "                           z= zLR, \n",
    "                           marker = dict(color='green', size=5), showlegend=False))\n",
    "\n",
    "\"\"\" intanto commentato per mantenere viz più veloce mentre faccio tutto il resto\n",
    "#Modello DT\n",
    "xDT = [cmDT[0][0]/N] #TP/N\n",
    "yDT = [cmDT[1][1]/N] #TN/N\n",
    "zDT = [cmDT[0][1]/N] #FP/N\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xDT, \n",
    "                           y= yDT, \n",
    "                           z= zDT, \n",
    "                           marker = dict(color='green', size=5), showlegend=False))\n",
    "\n",
    "#se poi voglio mettere tutti gli altri modelli li aggiungo qui \n",
    "#Modello NB\n",
    "\n",
    "#Modello KNN\n",
    "\n",
    "#Modello SVM \n",
    "\"\"\"\n",
    "\n",
    "#Per avere l'esempio di una confusion matrix \n",
    "#sono tutte relativamente buone confusion matrices \n",
    "#quindi faccio esempio di confusion matrix che uscirebbe da una classificazione non accurata \n",
    "#per far vedere la differenza \n",
    "xB = [cm_badc[0][0]/N] #TP/N\n",
    "yB = [cm_badc[1][1]/N] #TN/N\n",
    "zB = [cm_badc[0][1]/N] #FP/N\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xB, \n",
    "                           y= yB, \n",
    "                           z= zB, \n",
    "                           marker = dict(color='red', size=5), showlegend=False))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#SECONDA QUESTIONE\n",
    "#devo capire come distinguere le due sfumature per avere ABC e AOB verdi/blu\n",
    "#                                                        AOC e BOC arancione/gialli\n",
    "#le sfumature tral'altro lungo OC e lungo AB \n",
    "#-> gradiente come funzione lineare dell'indicatore\n",
    "\n",
    "\n",
    "#devo generare ogni possibile confusion matrix per ogni combinazione\n",
    "#di TP,TN,FP (diviso n)\n",
    "#calcolare mcc associato a ciascuna di questa matrice \n",
    "#rendere il colore \n",
    "\n",
    "#potrei dividere le due mesh (verde/blu e giallo/rosso)\n",
    "\n",
    "#verosimilmente discretizzo (1M points diceva) e per ogni punto calcolo MCC\n",
    "#http://al-roomi.org/3DPlot/index.html\n",
    "\n",
    "\n",
    "#piano passante per 3 punti\n",
    "#ax+by+cz+d=0\n",
    "#x+y+z-1=0 equazione del piano nostro http://al-roomi.org/3DPlot/index.html\n",
    "\n",
    "#-> la seconda questione poi la risolvo sotto (con meno punti di 1M perchè ci mette la vita altrimenti)\n",
    "\n",
    "#TODO: unire punto di performance dei modelli a tetraedro con tutte le confusion matrices sotto\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "#THIS RESULT IS GOOD BUT I WANT TO COLOR THE TETRAHEDRON ACCORDING TO THE PERFORMANCE METRIC (MCC, DOR, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb441e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c32addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE I GENERATE THE DATA FOR THE GRADIENT COLOR OF THE TETRAHEDRON  \n",
    "#CIOè MI CREO IL DATAFRAME CON LE 3 COORDINATE E L'ASSOCIATO MCC\n",
    "\n",
    "\n",
    "#devo capire come distinguere le due sfumature per avere ABC e AOB verdi/blu\n",
    "#                                                        AOC e BOC arancione/gialli\n",
    "#le sfumature tral'altro lungo OC e lungo AB \n",
    "#-> gradiente come funzione lineare dell'indicatore\n",
    "\n",
    "#start = timeit.default_timer()\n",
    "#devo generare ogni possibile confusion matrix per ogni combinazione\n",
    "#di TP,TN,FP (diviso n)\n",
    "#calcolare mcc associato a ciascuna di questa matrice \n",
    "#rendere il colore \n",
    "\n",
    "#potrei dividere le due mesh (verde/blu e giallo/rosso)\n",
    "\n",
    "#verosimilmente discretizzo (1M points diceva) \n",
    "#e per ogni punto calcolo MCC\n",
    "\n",
    "\n",
    "#piano passante per 3 punti\n",
    "#ax+by+cz+d=0\n",
    "#x+y+z-1=0 equazione del piano nostro http://al-roomi.org/3DPlot/index.html\n",
    "\n",
    "\n",
    "#definisco 3 vettori x,y,z discretizzati da 0 a 1\n",
    "xd = np.linspace(0,1, num=100) #metto intanto pochi punti\n",
    "yd = np.linspace(0,1, num=100)\n",
    "zd = np.linspace(0,1, num=100)\n",
    "\n",
    "#voglio creare un vettore di x,y,z per avere tutti i punti del cubo \n",
    "#lo faccio definendo \n",
    "#x>0 con x= 0->1\n",
    "#y>0     y= 0->1\n",
    "#z>0     z= 0->1\n",
    "\n",
    "#e poi filtrare per quelli che stanno sotto il piano x+y+z-1=0\n",
    "#cioè z < 1 - x - y (seconda condizione da soddisfare)\n",
    "#points = [xd.T,yd.T,zd.T] #per avere matrice di vettori colonna\n",
    "#points\n",
    "\n",
    "#points=np.meshgrid(xd,yd,zd,indexing='ij')\n",
    "#points\n",
    "\n",
    "all_p_array = np.array(np.meshgrid(xd, yd, zd)).T.reshape(-1,3)\n",
    "#len(all_p_array) just to check\n",
    "\n",
    "column_values = ['x','y','z']\n",
    "all_p_df = pd.DataFrame(data=all_p_array,\n",
    "                        columns=column_values)\n",
    "all_p_df\n",
    "#print(len(all_p_df))\n",
    "\n",
    "#adesso voglio droppare le righe se stanno sopra il piano\n",
    "#cioè se z > 1 -x -y\n",
    "filtered = all_p_df.query('z<1-x-y')\n",
    "filtered\n",
    "#ha senso che sia 1/5 perchè ne avrai che si ripetono 4 e uno in centro\n",
    "\n",
    "#aggiungo colonna MCC\n",
    "#sklearn usa le predizioni non le entries della confusion matrix \n",
    "#quindi lo ridefinisco \n",
    "#MCC = (TP*TN -FP*FN)/sqrt((TP+FP)(TP+FN)(TN+FP)(TN+FN))\n",
    "#x è TP quindi row.x\n",
    "#y è TN quindi row.y\n",
    "#z è FP quindi row.z\n",
    "#    FN = 1-FP-TP-TN quindi 1-row.z-row.x-row.y\n",
    "#è scaling invariant quindi facendo i conti n va via\n",
    "filtered['MCC'] = filtered.apply(\n",
    "    lambda row: round((row.x*row.y - row.z*(1-row.z-row.x-row.y))/math.sqrt((row.x+row.z)*(row.x+(1-row.z-row.x-row.y))*(row.y+row.z)*(row.y +(1-row.z-row.x-row.y))),3),\n",
    "    axis=1)\n",
    "\n",
    "filtered['MCC'] = filtered['MCC'].replace(np.nan, 0) #se un'intera riga o colonna è 0 \n",
    "                                                     #non è definito MCC ma limite tende a 0 quindi sostituisco\n",
    "\n",
    "filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2167546",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#UTILIZZANDO QUESTO DATAFRAME MI PLOTTO IL MODEL ON THE BASIS OF THE OBTAINED RESULTS (i.e. filtered dataframe)\n",
    "\n",
    "#SO FAR I ONLY HAVE TETRAHEDRON WITH THE MODELS AND THE TETRAHEDRON WITH THE GRADIENT SEPARATELY\n",
    "#I NEED TO COMBINE THE TWO VISUALIZATIONS IN ONE SINGLE VIEW\n",
    "\n",
    "\n",
    "#----------- Plot the models \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Mesh3d(\n",
    "        x=[0, 0, 0, 1], #verticalmente ho definito O, C, B, A\n",
    "        y=[0, 0, 1, 0],\n",
    "        z=[0, 1, 0, 0],\n",
    "        \n",
    "        #colorbar_title='z',\n",
    "        \n",
    "        #colorscale=[[0, 'gold'],\n",
    "        #            [0.5, 'mediumturquoise'],\n",
    "        #            [1, 'magenta']],\n",
    "        #colors = colorRamp(c(\"red\",'yellow','white','green','blue')),\n",
    "        \n",
    "        # Intensity of each vertex, which will be interpolated and color-coded\n",
    "        intensity=[0, 0.33, 0.66, 1],\n",
    "        \n",
    "        opacity = 0.1, #for transparency\n",
    "        \n",
    "        # i, j and k sono i vertici dei triangoli\n",
    "        # here we represent the 4 triangles of the tetrahedron surface\n",
    "        i=[0, 0, 0, 1],\n",
    "        j=[1, 2, 3, 2],\n",
    "        k=[2, 3, 1, 3],\n",
    "        name='y',\n",
    "        showscale=True\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "#PRIMA QUESTIONE \n",
    "#aggiungere il punto per la confusion matrix dello use case specifico \n",
    "#-> risolto, non metto tutti i modelli ma tipo i due migliori e uno meno performante (da confusion matrix esempio)\n",
    "\n",
    "#Modello LogReg \n",
    "N = sum(sum(cmLR))                  #confusion matrix entries divided by N\n",
    "xLR = [cmLR[0][0]/N] #TP/N\n",
    "yLR = [cmLR[1][1]/N] #TN/N\n",
    "zLR = [cmLR[0][1]/N] #FP/N\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xLR, \n",
    "                           y= yLR, \n",
    "                           z= zLR, \n",
    "                           marker = dict(color='green', size=5), showlegend=False))\n",
    "\n",
    "\n",
    "#Per avere l'esempio di una confusion matrix \n",
    "#sono tutte relativamente buone confusion matrices \n",
    "#quindi faccio esempio di confusion matrix che uscirebbe da una classificazione non accurata \n",
    "#per far vedere la differenza \n",
    "xB = [cm_badc[0][0]/N] #TP/N\n",
    "yB = [cm_badc[1][1]/N] #TN/N\n",
    "zB = [cm_badc[0][1]/N] #FP/N\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xB, \n",
    "                           y= yB, \n",
    "                           z= zB, \n",
    "                           marker = dict(color='red', size=5), showlegend=False))\n",
    "fig.show()\n",
    "\n",
    "\n",
    "#---------- COSTRUZIONE DEL TETRAEDRO CON LA SFUMATURA\n",
    "#---------- Da qui sotto solo per il tetraedro con tutte le confusion matrix e indicatore \n",
    "\n",
    "#SECONDA QUESTIONE\n",
    "#devo capire come distinguere le due sfumature per avere ABC e AOB verdi/blu\n",
    "#                                                        AOC e BOC arancione/gialli\n",
    "#le sfumature tral'altro lungo OC e lungo AB \n",
    "#-> gradiente come funzione lineare dell'indicatore\n",
    "\n",
    "\n",
    "#devo generare ogni possibile confusion matrix per ogni combinazione\n",
    "#di TP,TN,FP (diviso n)\n",
    "#calcolare mcc associato a ciascuna di questa matrice \n",
    "#rendere il colore \n",
    "\n",
    "#potrei dividere le due mesh (verde/blu e giallo/rosso)\n",
    "\n",
    "#verosimilmente discretizzo (1M points diceva) e per ogni punto calcolo MCC\n",
    "#http://al-roomi.org/3DPlot/index.html\n",
    "\n",
    "\n",
    "#piano passante per 3 punti\n",
    "#ax+by+cz+d=0\n",
    "#x+y+z-1=0 equazione del piano nostro http://al-roomi.org/3DPlot/index.html\n",
    "\n",
    "#-> la seconda questione poi la risolvo sotto (con meno punti di 1M perchè ci mette la vita altrimenti)\n",
    "\n",
    "#TODO: unire punto di performance dei modelli a tetraedro con tutte le confusion matrices sotto\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(filtered, \n",
    "                    x='x', \n",
    "                    y='y', \n",
    "                    z='z',\n",
    "                    #mode='markers',\n",
    "                    #marker = dict(size=12,\n",
    "                    #              #color=filtered['MCC'],\n",
    "                    #             colorscale='Viridis',\n",
    "                    #             opacity=0.8)\n",
    "                    \n",
    "                    #size = 'size',\n",
    "                    opacity = 0.3,\n",
    "                    color='MCC'\n",
    "                   )\n",
    "\n",
    "fig.update_traces(marker=dict(size=12,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='circle-open'))\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "#OK NOW THE THING IS THAT I WANT TO COMBINE THESE TWO VIZ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab5af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DA QUI LE VIZ SONO TUTTE COMMENTATE PER EVITARE CHE CI METTA TROPPO TEMPO A CARICARE QUANDO LO APRO \n",
    "\n",
    "#VANNO SCOMMENTATE ALL'OCCORRENZA (l'idea è fare un .py per 1) visualizzazione punti su tetraedro\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#GENERATI I DATI VOGLIO PLOTTARE UN TETRAEDRO \n",
    "#CON COLORE DIVERSO A SECONDA DELLA METRICA\n",
    "#E VOGLIO AGGIUNGERCI IL PUNTO IN BASE ALLA CONFUSION MATRIX \n",
    "#CHE VIENE INSERITA\n",
    "\n",
    "\n",
    "#l'ideale sarebbe stato arrivare a un'applicazione in cui uno sceglie \n",
    "#la metrica con cui visualizzare il tetraedro\n",
    "#inserisce la sua confusion matrix \n",
    "#e io gli visualizzo il risultato \n",
    "\n",
    "#QUESTA LA STRUTTURA CON IL COLORE SULLA BASE DELLA METRICA SCELTA \n",
    "#QUI MCC \n",
    "\n",
    "fig = px.scatter_3d(filtered, \n",
    "                    x='x', \n",
    "                    y='y', \n",
    "                    z='z',\n",
    "                    #mode='markers',\n",
    "                    #marker = dict(size=12,\n",
    "                    #              #color=filtered['MCC'],\n",
    "                    #             colorscale='Viridis',\n",
    "                    #             opacity=0.8)\n",
    "                    \n",
    "                    #size = 'size',\n",
    "                    opacity = 0.5,\n",
    "                    color='MCC'\n",
    "                   )\n",
    "\n",
    "fig.update_traces(marker=dict(size=12,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='circle-open'))\n",
    "\n",
    "\n",
    "\n",
    "#Qui aggiungo i punti per i modelli \n",
    "#Modello LogReg \n",
    "N = sum(sum(cmLR))                  #confusion matrix entries divided by N\n",
    "xLR = [cmLR[0][0]/N] #TP/N\n",
    "yLR = [cmLR[1][1]/N] #TN/N\n",
    "zLR = [cmLR[0][1]/N] #FP/N\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xLR, \n",
    "                           y= yLR, \n",
    "                           z= zLR, \n",
    "                           marker = dict(color='black', size=5), showlegend=False))\n",
    "\n",
    "\n",
    "#Modello DT\n",
    "xDT = [cmDT[0][0]/N] #TP/N\n",
    "yDT = [cmDT[1][1]/N] #TN/N\n",
    "zDT = [cmDT[0][1]/N] #FP/N\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xDT, \n",
    "                           y= yDT, \n",
    "                           z= zDT, \n",
    "                           marker = dict(color='black', size=5), showlegend=False))\n",
    "\n",
    "#Per avere l'esempio di una confusion matrix \n",
    "#sono tutte relativamente buone confusion matrices \n",
    "#quindi faccio esempio di confusion matrix che uscirebbe da una classificazione non accurata \n",
    "#per far vedere la differenza \n",
    "xB = [cm_badc[0][0]/N] #TP/N\n",
    "yB = [cm_badc[1][1]/N] #TN/N\n",
    "zB = [cm_badc[0][1]/N] #FP/N\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xB, \n",
    "                           y= yB, \n",
    "                           z= zB, \n",
    "                           marker = dict(color='black', size=5), showlegend=False))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "\n",
    "#THIS IS ACTUALLY THE RESULT I WANT BUT \n",
    "#I NEED THE POINTS TO BE MORE VISIBLE\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2580065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#SOLO DOT LOGREG\n",
    "fig = px.scatter_3d(filtered, \n",
    "                    x='x', \n",
    "                    y='y', \n",
    "                    z='z',\n",
    "                    #mode='markers',\n",
    "                    #marker = dict(size=12,\n",
    "                    #              #color=filtered['MCC'],\n",
    "                    #             colorscale='Viridis',\n",
    "                    #             opacity=0.8)\n",
    "                    \n",
    "                    #size = 'size',\n",
    "                    opacity = 0.2,\n",
    "                    color='MCC'\n",
    "                   )\n",
    "\n",
    "fig.update_traces(marker=dict(size=12,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='circle-open'))\n",
    "\n",
    "\n",
    "\n",
    "#Qui aggiungo i punti per i modelli \n",
    "#Modello LogReg \n",
    "N = sum(sum(cmLR))                  #confusion matrix entries divided by N\n",
    "xLR = [cmLR[0][0]/N] #TP/N\n",
    "yLR = [cmLR[1][1]/N] #TN/N\n",
    "zLR = [cmLR[0][1]/N] #FP/N\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xLR, \n",
    "                           y= yLR, \n",
    "                           z= zLR, \n",
    "                           marker = dict(color='black', size=5), showlegend=False))\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e4d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "#QUI TUTTI E 5 I MODELLI PER VALUTARE LA DISTANZA RELATIVA \n",
    "\n",
    "#Qui metto tutti e 5 i modelli \n",
    "fig = px.scatter_3d(filtered, \n",
    "                    x='x', \n",
    "                    y='y', \n",
    "                    z='z',\n",
    "                    #mode='markers',\n",
    "                    #marker = dict(size=12,\n",
    "                    #              #color=filtered['MCC'],\n",
    "                    #             colorscale='Viridis',\n",
    "                    #             opacity=0.8)\n",
    "                    \n",
    "                    #size = 'size',\n",
    "                    opacity = 0.2,\n",
    "                    color='MCC'\n",
    "                   )\n",
    "\n",
    "fig.update_traces(marker=dict(size=12,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='circle-open'))\n",
    "\n",
    "\n",
    "\n",
    "#Qui aggiungo i punti per i modelli \n",
    "#Modello LogReg \n",
    "N = sum(sum(cmLR))                  #confusion matrix entries divided by N\n",
    "xLR = [cmLR[0][0]/N] #TP/N\n",
    "yLR = [cmLR[1][1]/N] #TN/N\n",
    "zLR = [cmLR[0][1]/N] #FP/N\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xLR, \n",
    "                           y= yLR, \n",
    "                           z= zLR, \n",
    "                           marker = dict(color='black', size=5), showlegend=False))\n",
    "\n",
    "\n",
    "#Modello NB\n",
    "xNB = [cmNB[0][0]/N] #TP/N\n",
    "yNB = [cmNB[1][1]/N] #TN/N\n",
    "zNB = [cmNB[0][1]/N] #FP/N\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xNB, \n",
    "                           y= yNB, \n",
    "                           z= zNB, \n",
    "                           marker = dict(color='black', size=5), showlegend=False))\n",
    "\n",
    "#Modello KNN\n",
    "xKNN = [cmKNN[0][0]/N] #TP/N\n",
    "yKNN = [cmKNN[1][1]/N] #TN/N\n",
    "zKNN = [cmKNN[0][1]/N] #FP/N\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xKNN, \n",
    "                           y= yKNN, \n",
    "                           z= zKNN, \n",
    "                           marker = dict(color='black', size=5), showlegend=False))\n",
    "\n",
    "#Modello SVM\n",
    "xSVM= [cmSVM[0][0]/N] #TP/N\n",
    "ySVM = [cmSVM[1][1]/N] #TN/N\n",
    "zSVM = [cmSVM[0][1]/N] #FP/N\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xSVM, \n",
    "                           y= ySVM, \n",
    "                           z= zSVM, \n",
    "                           marker = dict(color='black', size=5), showlegend=False))\n",
    "\n",
    "#Modello DT\n",
    "xDT = [cmDT[0][0]/N] #TP/N\n",
    "yDT = [cmDT[1][1]/N] #TN/N\n",
    "zDT = [cmDT[0][1]/N] #FP/N\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(mode='markers', \n",
    "                           x= xDT, \n",
    "                           y= yDT, \n",
    "                           z= zDT, \n",
    "                           marker = dict(color='black', size=5), showlegend=False))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "\n",
    "#THIS IS ACTUALLY THE RESULT I WANT BUT \n",
    "#I NEED THE POINTS TO BE MORE VISIBLE\n",
    "\n",
    "\n",
    "#19 secondi\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9bad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the two visualisations \n",
    "#with DASH \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f45fdc4",
   "metadata": {},
   "source": [
    "# First application: global landscape for classifiers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ed0a9",
   "metadata": {},
   "source": [
    "Depending on my specific interests and application I can plot the gradient for alternative metrics which permits to appreciate the different global behaviour of the numerical indicator. Moreover through the colored tetrahedron it is easy to understand why the trustworthiness of the information provided by the Matthews Correlation Coefficient ($MCC$) is higher than other performance metrics (e.g $F_1$-score, accuracy)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------HERE I AM DOING THE SAME WITH THE F1 score \n",
    "#BECAUSE IDEALLY I WOULD LIKE TO MAKE A DASH APPLICATION WHERE YOU SELECT\n",
    "#THE METRIC WITH WHICH YOU WANT TO COLOUR THE TETRAHEDRON \n",
    "#AND THEN YOU ADD YOUR CONFUSION MATRIX \n",
    "#AND THE APP VISUALIZES IT FOR YOU \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#è il solito warning dello slice che non è troppo rilevante per ora \n",
    "\n",
    "#F1 score\n",
    "#F1 = 2*TP/(2*TP + FP + FN)\n",
    "#Notice: indendent from the TN (n° of samples correctly classified as negative)\n",
    "filtered['F1'] = filtered.apply(\n",
    "    lambda row: round((2*row.x)/(2*row.x+row.z+(1-row.z-row.x-row.y)),3),\n",
    "    axis=1)\n",
    "\n",
    "#results:\n",
    "#filtered\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(filtered, \n",
    "                    x='x', \n",
    "                    y='y', \n",
    "                    z='z',\n",
    "                    #mode='markers',\n",
    "                    #marker = dict(size=12,\n",
    "                    #              #color=filtered['MCC'],\n",
    "                    #             colorscale='Viridis',\n",
    "                    #             opacity=0.8)\n",
    "                    \n",
    "                    #size = 'size',\n",
    "                    opacity = 0.2,\n",
    "                    color='F1'\n",
    "                   )\n",
    "\n",
    "fig.update_traces(marker=dict(size=12,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='circle-open'))\n",
    "\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e374a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----- SAME WITH THE ACCURACY SCORE \n",
    "filtered\n",
    "\n",
    "filtered['accuracy'] = filtered.apply(\n",
    "    lambda row: round((row.x+row.y)/(row.x + row.y + row.z + (1-row.z-row.x-row.y)),3),\n",
    "    axis=1)\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(filtered, \n",
    "                    x='x', \n",
    "                    y='y', \n",
    "                    z='z',\n",
    "                    #mode='markers',\n",
    "                    #marker = dict(size=12,\n",
    "                    #              #color=filtered['MCC'],\n",
    "                    #             colorscale='Viridis',\n",
    "                    #             opacity=0.8)\n",
    "                    \n",
    "                    #size = 'size',\n",
    "                    opacity = 0.2,\n",
    "                    color='accuracy'\n",
    "                   )\n",
    "\n",
    "fig.update_traces(marker=dict(size=12,\n",
    "                              line=dict(width=2,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='circle-open'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2f8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa0c732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
